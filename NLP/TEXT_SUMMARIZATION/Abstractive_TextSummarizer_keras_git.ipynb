{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "ZHt3stRsv5_5",
    "outputId": "2e7256d0-1709-4f45-bd30-c03ea59e56eb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "dJaUpO3cDSDp",
    "outputId": "e68ae6ea-416e-4a48-85db-b3f573c4e57b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.38.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "beNhm-WMDSzM",
    "outputId": "6116a421-d6fc-4cef-949e-6b530d255456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘.kaggle’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir .kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "d354Mlj8DS14",
    "outputId": "20d4cb46-ef61-4cf7-90ff-ee76513678c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yPUM7c70DS5a"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "token = {\"username\":\"\",\"key\":\"\"}\n",
    "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
    "  json.dump(token, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzhKBkOhDS8T"
   },
   "outputs": [],
   "source": [
    "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eoA5V0cnDS_Q",
    "outputId": "2d68a8d6-a547-4b2e-d4fb-4cb8fcd840d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- path is now set to: {/content}\n"
     ]
    }
   ],
   "source": [
    "!kaggle config set -n path -v{/content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Z2vXdq3DTCu"
   },
   "outputs": [],
   "source": [
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vBdnscJnDTGM",
    "outputId": "95d8f0d3-87a5-441e-8f90-e62a593de42c"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets list -s amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METHOD 1\n",
    "This is one of the method to directly download the data from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LesTGr2JDTLf",
    "outputId": "7028e326-2c7a-489e-d57c-67602ef53a4c"
   },
   "outputs": [],
   "source": [
    "!kaggle competitions download -c snap/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xfScpfRxDTSe"
   },
   "source": [
    "### METHOD 2\n",
    "Another way to mount the google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "qfTi15yfz0tv",
    "outputId": "36cf7687-a26e-42ce-a1ec-426d5e6fdb3e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XAWn-myWxRP7",
    "outputId": "3da7d883-eb2f-4f45-e05b-a4dab1e6af98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database.sqlite  hashes.txt  Reviews.csv\n"
     ]
    }
   ],
   "source": [
    "!ls /content/drive/My\\ Drive/amazon_data/amazon-fine-food-reviews/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O4ociIrw1oAg",
    "outputId": "8bdc670d-3aab-4428-d6d4-9a4da0ab869e"
   },
   "source": [
    "### METHOD 3\n",
    "Upload the files directly to colab so that data can be accessed quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Qc1XUMaDDTOd",
    "outputId": "2289d414-bdcf-4b2d-ff61-3e5a96d56f91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_data.zip  drive\tsample_data\n"
     ]
    }
   ],
   "source": [
    "# So we use method 3 to proceed\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpUdE_R3v6AE"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(\"amazon_data.zip\", 'r')\n",
    "zip_ref.extractall(\"amazon\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jOVS2jQfUv23",
    "outputId": "907c2784-913c-4ac4-d421-67ca88a4e44f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database.sqlite  hashes.txt  Reviews.csv\n"
     ]
    }
   ],
   "source": [
    "!ls amazon/amazon_data/amazon-fine-food-reviews/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOE2KBjzv6AN"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nmNoffu-BscG",
    "outputId": "21658364-af1a-4947-a029-ae6d8027ef34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SfDPuTJsB36O",
    "outputId": "82395a6f-4c65-404d-8f1c-4997d3c1347f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon\tamazon_data.zip  drive\tsample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xDbV_sd4v6AT"
   },
   "outputs": [],
   "source": [
    "# using SQLite Table to read data.\n",
    "con = sqlite3.connect('amazon/amazon_data/amazon-fine-food-reviews/database.sqlite')\n",
    "\n",
    "# filtering only positive and negative reviews i.e. \n",
    "# not taking into consideration those reviews with Score=3\n",
    "# SELECT * FROM Reviews WHERE Score != 3 LIMIT 500000, will give top 500000 data points\n",
    "# you can change the number to any other number based on your computing power\n",
    "\n",
    "# filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3 LIMIT 500000\"\"\", con) \n",
    "# for tsne assignment you can take 5k data points\n",
    "\n",
    "filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3 LIMIT 5000\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3NYPIwQv6AZ"
   },
   "outputs": [],
   "source": [
    "#Sorting data according to ProductId in ascending order\n",
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VguFQShov6Af",
    "outputId": "78d49d75-bd8d-4945-e55f-009faf788fc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4986, 10)"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ENkraP1Wv6Ak"
   },
   "outputs": [],
   "source": [
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vEPdMf40v6Ap",
    "outputId": "cdf65dc2-ad2b-4583-d0df-081b92e85786"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4986, 10)"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yzuoZ1rMv6At"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofbYKGcGv6Ay"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f309opDKv6A3"
   },
   "outputs": [],
   "source": [
    "# https://gist.github.com/sebleier/554280\n",
    "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
    "# <br /><br /> ==> after the above steps, we are getting \"br br\"\n",
    "# we are including them into stop words list\n",
    "# instead of <br /> if we have <br/> these tags would have revmoved in the 1st step\n",
    "\n",
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sg2zGoKkv6A8",
    "outputId": "6e0906c7-52de-4c1e-b3bf-1917e71b27de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4986/4986 [00:01<00:00, 3566.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "preprocessed_reviews = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(final['Text'].values):\n",
    "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "    sentance = decontracted(sentance)\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "    preprocessed_reviews.append(sentance.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BGVb46Eyv6BI",
    "outputId": "91d3487a-40f1-4b23-cc6f-4b818fccac74"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4986/4986 [00:00<00:00, 5009.36it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_summary = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(final['Summary'].values):\n",
    "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "    sentance = decontracted(sentance)\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "    preprocessed_summary.append(sentance.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Kip8Mb2yv6BN",
    "outputId": "b253618f-caf3-4ac3-a36c-077d34ddc2d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding, \\\n",
    "  Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QkWEsYZmv6BR"
   },
   "outputs": [],
   "source": [
    "def softmax_over_time(x):\n",
    "    assert(K.ndim(x) > 2)\n",
    "    e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
    "    s = K.sum(e, axis=1, keepdims=True)\n",
    "    return e / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7p9PycK_v6BV"
   },
   "outputs": [],
   "source": [
    "# config\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 256\n",
    "LATENT_DIM_DECODER = 256 # idea: make it different to ensure things all fit together properly!\n",
    "NUM_SAMPLES = 4986\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wC0_iWRmv6BY"
   },
   "outputs": [],
   "source": [
    "target_texts = [] # sentence in target language\n",
    "target_texts_inputs = [] # sentence in target language offset by 1\n",
    "\n",
    "# Adding <sos> & <eos> to preprocessed_summary\n",
    "# target_texts --> With <eos>\n",
    "# target_texts_inputs --> With <sos>\n",
    "\n",
    "for i in preprocessed_summary:\n",
    "    target_text = i + ' <eos>'\n",
    "    target_text_input = '<sos> ' + i\n",
    "    target_texts.append(target_text)\n",
    "    target_texts_inputs.append(target_text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XnwdzRCIv6Bc"
   },
   "outputs": [],
   "source": [
    "input_texts = preprocessed_reviews.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "z3j1UO_0v6Be",
    "outputId": "59bf1e7f-fee9-4d70-fd30-3395ce3b800d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13015 unique input tokens.\n"
     ]
    }
   ],
   "source": [
    "# tokenize the inputs\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "\n",
    "# get the word to index mapping for input language\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73SBesfqv6Bi"
   },
   "outputs": [],
   "source": [
    "# determine maximum length input sequence\n",
    "max_len_input = max(len(s) for s in input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "A6-iG1Wjv6Bl",
    "outputId": "84c6dee2-41be-40d0-d203-20bb23dd9b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras_preprocessing.text.Tokenizer'>\n",
      "<class 'list'>\n",
      "4986\n",
      "39\n",
      "[7, 240, 5417, 5418, 5419, 414, 1147, 3818, 7211, 144, 2418, 86, 1898]\n",
      "('one', 6)\n",
      "('would', 8)\n"
     ]
    }
   ],
   "source": [
    "# As explained below\n",
    "### input_sequences \n",
    "# --> Length 4986 means 4986 sentences\n",
    "# --> Each sentences represents in numerical format using tokenizer with variable length\n",
    "\n",
    "### word2idx_inputs\n",
    "# --> It is dictionary with key as word and value as numerical unique representation\n",
    "\n",
    "print(type(tokenizer_inputs))\n",
    "print(type(input_sequences))\n",
    "print(len(input_sequences))\n",
    "print(len(input_sequences[2]))\n",
    "print((input_sequences[0]))\n",
    "print(list(word2idx_inputs.items())[5])\n",
    "print(list(word2idx_inputs.items())[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zJc--yIGv6Br",
    "outputId": "a436229a-b80f-4473-c969-deb1f621bc0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2971 unique output tokens.\n"
     ]
    }
   ],
   "source": [
    "# tokenize the outputs\n",
    "# don't filter out special characters\n",
    "# otherwise <sos> and <eos> won't appear\n",
    "\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs)\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n",
    "\n",
    "# get the word to index mapping for output language\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
    "\n",
    "# store number of output words for later\n",
    "# remember to add 1 since indexing starts at 1\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "# determine maximum length output sequence\n",
    "max_len_target = max(len(s) for s in target_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "colab_type": "code",
    "id": "J0_vLAgTv6Bv",
    "outputId": "1e665123-aa24-4ff7-a2f3-98b6a94daa43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "<class 'keras_preprocessing.text.Tokenizer'>\n",
      "========================================================================================================================\n",
      "# target_sequences\n",
      "# --> It is sequences with <eos>\n",
      "# --> Length 4986 as total sentences are 4986\n",
      "# --> Each sentences is of different length\n",
      "<class 'list'>\n",
      "4986\n",
      "5\n",
      "[1317, 1318, 157, 1319, 1]\n",
      "========================================================================================================================\n",
      "# target_sequences_inputs\n",
      "# --> It have sequences with <sos>\n",
      "# --> Length 4986 as total sentences are 4986\n",
      "# --> Each sentences is of different length\n",
      "<class 'list'>\n",
      "4986\n",
      "5\n",
      "[2, 1317, 1318, 157, 1319]\n",
      "========================================================================================================================\n",
      "# word2idx_outputs\n",
      "# --> It is Dictionary with key word and value as unique numeric value\n",
      "<class 'dict'>\n",
      "('<eos>', 1)\n",
      "('<sos>', 2)\n",
      "('great', 3)\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('='* 120)\n",
    "# tokenizer_outputs\n",
    "# --> It is tokenizer use to convert word to unique numerical value\n",
    "print(type(tokenizer_outputs))\n",
    "print('='* 120)\n",
    "\n",
    "print('# target_sequences')\n",
    "print('# --> It is sequences with <eos>')\n",
    "print('# --> Length 4986 as total sentences are 4986')\n",
    "print('# --> Each sentences is of different length')\n",
    "print(type(target_sequences))\n",
    "print(len(target_sequences))\n",
    "print(len(target_sequences[20]))\n",
    "print((target_sequences[20]))\n",
    "print('='* 120)\n",
    "\n",
    "print('# target_sequences_inputs')\n",
    "print('# --> It have sequences with <sos>')\n",
    "print('# --> Length 4986 as total sentences are 4986')\n",
    "print('# --> Each sentences is of different length')\n",
    "print(type(target_sequences_inputs))\n",
    "print(len(target_sequences_inputs))\n",
    "print(len(target_sequences_inputs[20]))\n",
    "print((target_sequences_inputs[20]))\n",
    "print('='* 120)\n",
    "\n",
    "print('# word2idx_outputs')\n",
    "print('# --> It is Dictionary with key word and value as unique numeric value')\n",
    "print(type(word2idx_outputs))\n",
    "print(list(word2idx_outputs.items())[0])\n",
    "print(list(word2idx_outputs.items())[1])\n",
    "print(list(word2idx_outputs.items())[2])\n",
    "print('='* 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "Xss4DK_tv6Bx",
    "outputId": "237bb160-6499-42b8-c932-9e464f893ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "<class 'numpy.ndarray'>\n",
      "decoder_data[0]: [   2 1309 1310    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "decoder_data.shape: (4986, 20)\n",
      "========================================================================================================================\n",
      "<class 'numpy.ndarray'>\n",
      "decoder_targets[0]: [1309 1310    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "decoder_targets.shape: (4986, 20)\n",
      "========================================================================================================================\n",
      "<class 'numpy.ndarray'>\n",
      "encoder_data.shape: (4986, 486)\n",
      "encoder_data[0]: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    7  240 5417\n",
      " 5418 5419  414 1147 3818 7211  144 2418   86 1898]\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "# According to max len padding the sequences\n",
    "print('='* 120)\n",
    "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
    "print(type(decoder_inputs))\n",
    "print(\"decoder_data[0]:\", decoder_inputs[0])\n",
    "print(\"decoder_data.shape:\", decoder_inputs.shape)\n",
    "print('='* 120)\n",
    "\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')\n",
    "print(type(decoder_targets))\n",
    "print(\"decoder_targets[0]:\", decoder_targets[0])\n",
    "print(\"decoder_targets.shape:\", decoder_targets.shape)\n",
    "print('='* 120)\n",
    "\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(type(encoder_inputs))\n",
    "print(\"encoder_data.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_data[0]:\", encoder_inputs[0])\n",
    "print('='* 120)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-n5Y99rv6B1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "G6-rDTQ6v6B4",
    "outputId": "ba7ddbde-49ee-4898-e1aa-fedaa7d8ffc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# store all the pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(\"amazon/amazon_data/glove/glove.6B.100d.txt\", encoding='utf8', errors = 'ignore') as f:\n",
    "    # is just a space-separated text file in the format:\n",
    "    # word vec[0] vec[1] vec[2] ...\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "UcwBqse0v6B7",
    "outputId": "b10223a7-5c21-42ab-a1fb-77874ab22ea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare embedding matrix\n",
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "print('prepare embedding matrix')\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i < MAX_NUM_WORDS:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVE35Khbv6B-"
   },
   "outputs": [],
   "source": [
    "# create embedding layer\n",
    "embedding_layer = Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix], input_length=max_len_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqT_xNVMv6CC"
   },
   "outputs": [],
   "source": [
    "# create targets, since we cannot use sparse\n",
    "# categorical cross entropy when we have sequences\n",
    "decoder_targets_one_hot = np.zeros((len(input_texts),max_len_target,num_words_output),dtype='float32')\n",
    "\n",
    "# assign the values\n",
    "for i, d in enumerate(decoder_targets):\n",
    "    # Here d is sentence and i is index\n",
    "    # example [1309 1310    1    0    0    0    0    0    0    0    0    0    0    0   0    0    0    0    0    0]\n",
    "    for t, word in enumerate(d):\n",
    "        # Here t is index of each word in d and word is unique numeric value\n",
    "        # if d is --> [1309 1310    1    0    0    0    0    0    0    0    0    0    0    0   0    0    0    0    0    0]\n",
    "        # then t is 0 --> 1309 is word\n",
    "        # then t is 1 --> 1310 is word\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "I87YXoc2v6CF",
    "outputId": "abfb4991-407b-47a2-a07a-1cdba22899b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "colab_type": "code",
    "id": "PNHCCinov6CH",
    "outputId": "3a6e952a-602e-4899-c52b-77f60c28f6fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3772644434745736421\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2266911202489989997\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16162767323491671642\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15701463552\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6687883656335654878\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5XoHlXNv6CL"
   },
   "outputs": [],
   "source": [
    "##### build the model #####\n",
    "\n",
    "# Set up the encoder - simple!\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = Bidirectional(LSTM( LATENT_DIM, return_sequences=True,dropout=0.5,))\n",
    "encoder_outputs = encoder(x)\n",
    "\n",
    "\n",
    "# Set up the decoder - not so simple\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "\n",
    "# this word embedding will not use pre-trained vectors\n",
    "# although you could\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1uNPyivv6CO"
   },
   "outputs": [],
   "source": [
    "######### Attention #########\n",
    "# Attention layers need to be global because\n",
    "# they will be repeated Ty times at the decoder\n",
    "attn_repeat_layer = RepeatVector(max_len_input)\n",
    "attn_concat_layer = Concatenate(axis=-1)\n",
    "attn_dense1 = Dense(10, activation='tanh')\n",
    "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
    "attn_dot = Dot(axes=1) # to perform the weighted sum of alpha[t] * h[t]\n",
    "\n",
    "def one_step_attention(h, st_1):\n",
    "    # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
    "    # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
    "    # copy s(t-1) Tx times\n",
    "    # now shape = (Tx, LATENT_DIM_DECODER)\n",
    "    st_1 = attn_repeat_layer(st_1)\n",
    "    # Concatenate all h(t)'s with s(t-1)\n",
    "    # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
    "    x = attn_concat_layer([h, st_1])\n",
    "    # Neural net first layer\n",
    "    x = attn_dense1(x)\n",
    "    # Neural net second layer with special softmax over time\n",
    "    alphas = attn_dense2(x)\n",
    "    # \"Dot\" the alphas and the h's\n",
    "    # Remember a.dot(b) = sum over a[t] * b[t]\n",
    "    context = attn_dot([alphas, h])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zQHSTr6v6CR"
   },
   "outputs": [],
   "source": [
    "# define the rest of the decoder (after attention)\n",
    "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True,dropout=0.5)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "\n",
    "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
    "context_last_word_concat_layer = Concatenate(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fAfMJAmqv6CT"
   },
   "outputs": [],
   "source": [
    "# Unlike previous seq2seq, we cannot get the output\n",
    "# all in one step\n",
    "# Instead we need to do Ty steps\n",
    "# And in each of those steps, we need to consider\n",
    "# all Tx h's\n",
    "\n",
    "# s, c will be re-assigned in each iteration of the loop\n",
    "s = initial_s\n",
    "c = initial_c\n",
    "\n",
    "# collect outputs in a list at first\n",
    "outputs = []\n",
    "for t in range(max_len_target): # Ty times\n",
    "    # get the context using attention\n",
    "    context = one_step_attention(encoder_outputs, s)\n",
    "    # we need a different layer for each time step\n",
    "    selector = Lambda(lambda x: x[:, t:t+1])\n",
    "    xt = selector(decoder_inputs_x)\n",
    "    # combine \n",
    "    decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "    # pass the combined [context, last word] into the LSTM\n",
    "    # along with [s, c]\n",
    "    # get the new [s, c] and output\n",
    "    o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
    "    # final dense layer to get next word prediction\n",
    "    decoder_outputs = decoder_dense(o)\n",
    "    outputs.append(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tUuxj1S0v6CW"
   },
   "outputs": [],
   "source": [
    "# 'outputs' is now a list of length Ty\n",
    "# each element is of shape (batch size, output vocab size)\n",
    "# therefore if we simply stack all the outputs into 1 tensor\n",
    "# it would be of shape T x N x D\n",
    "# we would like it to be of shape N x T x D\n",
    "\n",
    "def stack_and_transpose(x):\n",
    "    # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n",
    "    x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
    "    x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now batch_size x T x output_vocab_size\n",
    "    return x\n",
    "\n",
    "# make it a layer\n",
    "stacker = Lambda(stack_and_transpose)\n",
    "outputs = stacker(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhEmF1Ofv6CZ"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhGoWNE7v6Cd"
   },
   "outputs": [],
   "source": [
    "final_weights_path = 'best_modelAmazon.h5'\n",
    "\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint(final_weights_path, monitor='val_loss', verbose=1, save_best_only=True),\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=1),TensorBoard(log_dir='Graph', histogram_freq=1, write_graph=True, write_images=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "colab_type": "code",
    "id": "uiiA4F6Kv6Cf",
    "outputId": "a9d89d70-fcae-4a59-8551-accb6dd060a9"
   },
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "#tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tvT1UvBcv6Cj"
   },
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = Model(\n",
    "  inputs=[\n",
    "    encoder_inputs_placeholder,\n",
    "    decoder_inputs_placeholder,\n",
    "    initial_s, \n",
    "    initial_c,\n",
    "  ],\n",
    "  outputs=outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TjOh-CXyv6Cm",
    "outputId": "aab53836-2518-4e8c-cf81-740c46990c58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3988 samples, validate on 998 samples\n",
      "Epoch 1/100\n",
      " 128/3988 [..............................] - ETA: 7:14 - loss: 7.9326 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (2.688329). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3988/3988 [==============================] - 141s 35ms/step - loss: 1.6359 - val_loss: 1.2131\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.21313, saving model to best_modelAmazon.h5\n",
      "Epoch 2/100\n",
      "3988/3988 [==============================] - 128s 32ms/step - loss: 1.1437 - val_loss: 1.1389\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.21313 to 1.13894, saving model to best_modelAmazon.h5\n",
      "Epoch 3/100\n",
      "3988/3988 [==============================] - 127s 32ms/step - loss: 1.0449 - val_loss: 1.1226\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.13894 to 1.12264, saving model to best_modelAmazon.h5\n",
      "Epoch 4/100\n",
      "3988/3988 [==============================] - 127s 32ms/step - loss: 1.0202 - val_loss: 1.1399\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.12264\n",
      "Epoch 5/100\n",
      "3988/3988 [==============================] - 128s 32ms/step - loss: 1.0037 - val_loss: 1.1361\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.12264\n",
      "Epoch 6/100\n",
      "3988/3988 [==============================] - 126s 32ms/step - loss: 0.9916 - val_loss: 1.1084\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.12264 to 1.10839, saving model to best_modelAmazon.h5\n",
      "Epoch 7/100\n",
      "3988/3988 [==============================] - 127s 32ms/step - loss: 0.9794 - val_loss: 1.1136\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.10839\n",
      "Epoch 8/100\n",
      "3988/3988 [==============================] - 128s 32ms/step - loss: 0.9680 - val_loss: 1.1085\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.10839\n",
      "Epoch 9/100\n",
      "3988/3988 [==============================] - 127s 32ms/step - loss: 0.9564 - val_loss: 1.1013\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.10839 to 1.10135, saving model to best_modelAmazon.h5\n",
      "Epoch 10/100\n",
      "3988/3988 [==============================] - 126s 32ms/step - loss: 0.9402 - val_loss: 1.1177\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.10135\n",
      "Epoch 11/100\n",
      "3988/3988 [==============================] - 126s 32ms/step - loss: 0.9249 - val_loss: 1.1094\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.10135\n",
      "Epoch 12/100\n",
      "3988/3988 [==============================] - 126s 31ms/step - loss: 0.9093 - val_loss: 1.1112\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.10135\n",
      "Epoch 13/100\n",
      "3988/3988 [==============================] - 125s 31ms/step - loss: 0.8936 - val_loss: 1.1089\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.10135\n",
      "Epoch 14/100\n",
      "3988/3988 [==============================] - 126s 32ms/step - loss: 0.8770 - val_loss: 1.0989\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.10135 to 1.09895, saving model to best_modelAmazon.h5\n",
      "Epoch 15/100\n",
      "3988/3988 [==============================] - 126s 32ms/step - loss: 0.8618 - val_loss: 1.0982\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.09895 to 1.09821, saving model to best_modelAmazon.h5\n",
      "Epoch 16/100\n",
      "3988/3988 [==============================] - 128s 32ms/step - loss: 0.8480 - val_loss: 1.1116\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.09821\n",
      "Epoch 17/100\n",
      "3988/3988 [==============================] - 126s 32ms/step - loss: 0.8335 - val_loss: 1.1040\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.09821\n",
      "Epoch 18/100\n",
      "3988/3988 [==============================] - 126s 32ms/step - loss: 0.8194 - val_loss: 1.1058\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.09821\n",
      "Epoch 19/100\n",
      "3988/3988 [==============================] - 127s 32ms/step - loss: 0.8065 - val_loss: 1.1102\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.09821\n",
      "Epoch 20/100\n",
      "3988/3988 [==============================] - 126s 32ms/step - loss: 0.7939 - val_loss: 1.1049\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.09821\n",
      "Epoch 21/100\n",
      "3988/3988 [==============================] - 126s 32ms/step - loss: 0.7818 - val_loss: 1.1098\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.09821\n",
      "Epoch 22/100\n",
      "3988/3988 [==============================] - 127s 32ms/step - loss: 0.7712 - val_loss: 1.1157\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.09821\n",
      "Epoch 23/100\n",
      "3988/3988 [==============================] - 127s 32ms/step - loss: 0.7587 - val_loss: 1.1117\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.09821\n",
      "Epoch 24/100\n",
      "3988/3988 [==============================] - 125s 31ms/step - loss: 0.7474 - val_loss: 1.1204\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.09821\n",
      "Epoch 25/100\n",
      "3988/3988 [==============================] - 127s 32ms/step - loss: 0.7368 - val_loss: 1.1108\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.09821\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=\"rmsprop\", loss='categorical_crossentropy')\n",
    "\n",
    "# train the model\n",
    "z = np.zeros((NUM_SAMPLES, LATENT_DIM_DECODER)) # initial [s, c]\n",
    "r = model.fit(\n",
    "  [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
    "  batch_size=64,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=0.2,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "Kk8BE6KFv6Co",
    "outputId": "c9dd1d4f-5928-4278-9b17-4274264a4d25"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yijdS00Hv6Cr"
   },
   "outputs": [],
   "source": [
    "##### Make predictions #####\n",
    "# As with the poetry example, we need to create another model\n",
    "# that can take in the RNN state and previous word as input\n",
    "# and accept a T=1 sequence.\n",
    "\n",
    "# The encoder will be stand-alone\n",
    "# From this we will get our initial decoder hidden state\n",
    "# i.e. h(1), ..., h(Tx)\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
    "\n",
    "# next we define a T=1 decoder model\n",
    "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# no need to loop over attention steps this time because there is only one step\n",
    "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
    "\n",
    "# combine context with last word\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
    "\n",
    "# lstm and final dense\n",
    "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "decoder_outputs = decoder_dense(o)\n",
    "\n",
    "\n",
    "# note: we don't really need the final stack and tranpose\n",
    "# because there's only 1 output\n",
    "# it is already of size N x D\n",
    "# no need to make it 1 x N x D --> N x 1 x D\n",
    "\n",
    "\n",
    "\n",
    "# create the model object\n",
    "decoder_model = Model(\n",
    "  inputs=[\n",
    "    decoder_inputs_single,\n",
    "    encoder_outputs_as_input,\n",
    "    initial_s, \n",
    "    initial_c\n",
    "  ],\n",
    "  outputs=[decoder_outputs, s, c]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6eTIwB9Zv6Cv"
   },
   "outputs": [],
   "source": [
    "# map indexes back into real words\n",
    "# so we can view the results\n",
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLEVFqDSv6Cy"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    enc_out = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    # NOTE: tokenizer lower-cases all words\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "    \n",
    "    # if we get this we break\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "    # [s, c] will be updated in each loop iteration\n",
    "    s = np.zeros((1, LATENT_DIM_DECODER))\n",
    "    c = np.zeros((1, LATENT_DIM_DECODER))\n",
    "    \n",
    "    # Create the translation\n",
    "    output_sentence = []\n",
    "    for _ in range(max_len_target):\n",
    "        o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
    "        # Get next word\n",
    "        idx = np.argmax(o.flatten())\n",
    "        # End sentence of EOS\n",
    "        if eos == idx:\n",
    "            break\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_trans[idx]\n",
    "            output_sentence.append(word)\n",
    "        # Update the decoder input\n",
    "        # which is just the word just generated\n",
    "        target_seq[0, 0] = idx\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TbB2inlwv6C2",
    "outputId": "4c8d4c16-79ee-4973-b9c5-3df6fd0f022f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: erin baker products fruit nut mini breakfast cookie favorite one mini breakfast cookie calories cup coffee morning feel satisfied ready start day healthy low caloreis super delicious makes product work try like\n",
      "Predicted translation: best coffee ever\n",
      "Actual translation: healthy breakfast lover <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: item great price tastes great thing could make product better little plastic cup recyclable compostable\n",
      "Predicted translation: great product\n",
      "Actual translation: grandkids love <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: erin baker products favorite family breakfast cookie mini great snacks coffee breaks especially good traveling denser product regular cookie nice chewy filling calories\n",
      "Predicted translation: great waffle mix\n",
      "Actual translation: breakfast cookies <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: not work windows tried reinstating software no surprise di not work waste time money aware issue\n",
      "Predicted translation: not work\n",
      "Actual translation: not work windows <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: must admit first ordered bread new panasonic bread maker not expecting anything potato bread buy nearby store however ever surprised absolutely best stuff organic butter piled high properly melted par ambrosia could not believe good since first loaf made breads generally excellent none quite level potato bread really good perhaps credit goes new bread machine highly recommended general info package makes pound loaf machine recommended setting basic loaf bakes hours also flour non gmo verified labelled\n",
      "Predicted translation: great\n",
      "Actual translation: great glorious super wonderful delicious bread <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: honey dijon chips bring terrific balance salty tangy sweet crunchy brands tried use much mustard flavor overpowers honey dijon pairing chips make great side dish bbq plate baked beans coleslaw potato salad grilled meat naturally also go great beer oregonian proud share delectable snacks friends especially living outside state not experienced gourmet chips tell kettle brand potato chips microbrews beer kettle brand potato chips unmistakable light gold color rich flavor amazing crunch kettle brand chips also healthier snacking option major chip brands kettle brand chips not trans fats msg artificial flavors colorings company also line organic potato chips products certified kosher also recommend kettle chips flavors annette solomon reporter salem statesman journal recently noted glass wine goes nicely chips solomon wrote could missing wonderful pairing chips spicy would want select semi sweet white wine also moderate amount acid subdue strong flavors ginger lime garlic cilantro without powering classically german style riesling fits parameters perfectly\n",
      "Predicted translation: delicious\n",
      "Actual translation: crunchy salty sweet finally superbowl snack scooores <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: love sauce sweet molasses tiny kick heat use make hawaiian chicken pork time never authentic jamaican jerk not vouch accuracy whole family loves one\n",
      "Predicted translation: best sauce\n",
      "Actual translation: maybe not authentic yummy <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: strawberry twizzlers guilty pleasure yummy six pounds around son\n",
      "Predicted translation: great chips\n",
      "Actual translation: strawberry twizzlers yummy <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: would rate better average since not fan flavored coffees would give rating taste artificial weird like flavored coffees regular coffees good better many really liked amazonia africana medium roasts not much colombian dark roast eclipse mexican french roast good made ice coffee strong not bitter not care costa rican light roast artificial taste house blend good nothing write home hate decaf used k cup water plants far taste goes no idea plants perked chocolate raspberry went nicely chocolate cake batter place water delicious priced right would buy\n",
      "Predicted translation: best\n",
      "Actual translation: nice variety guests try flavor <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: coffee great alternative someone acid reflux ulcer problems low acid allows still caffine day maybe not smooth tasting usual blend thankful really close taste\n",
      "Predicted translation: great tea\n",
      "Actual translation: great alternative coffee drinkers <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: powdered green tea lemon ginger provides quick daily source antioxidant ingredients desired higher concentration without bother brewing tea bags simply pour water bottle shake way product used available local health food stores no longer carried much easier cost effective bought quantity amazon\n",
      "Predicted translation: great tea\n",
      "Actual translation: powdered green tea stash <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: product strong taste crayola crayons process trying different brands coconut oils cooking purposes upon opening plastic container aroma crayons immediately fills room flavor permeates food cooked suspect source problem plastic used plastic container not experienced brands purchased date favorite coconut oil distributed barleans flavor fantastic however not supply gallon sized tub dr mercola best product size category\n",
      "Predicted translation: great product\n",
      "Actual translation: disappointed <eos>\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  # Do some test translations\n",
    "  i = np.random.choice(len(input_texts))\n",
    "  input_seq = encoder_inputs[i:i+1]\n",
    "  translation = decode_sequence(input_seq)\n",
    "  print('-')\n",
    "  print('Input sentence:', input_texts[i])\n",
    "  print('Predicted translation:', translation)\n",
    "  print('Actual translation:', target_texts[i])\n",
    "\n",
    "  ans = input(\"Continue? [Y/n]\")\n",
    "  if ans and ans.lower().startswith('n'):\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McaZBU_xv6C5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AmazonTextSummarizer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
